

- check for sticked unexpected tokens : OK
- split the line into a linked list with a node for each token: OK
- give to each token a type : OK


Parsing : 
- check tokens order and manage error : to test
- convert the token struct to a cmd struct : 
- expend the user variables with the path :

- when an error happend on tokenizer or paser:
	-> free all leaks
	-> write the error : OK
	-> exit the program : OK